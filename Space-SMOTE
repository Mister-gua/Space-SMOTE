import numpy as np
from sklearn.neighbors import NearestNeighbors
import warnings
from sklearn import preprocessing
warnings.filterwarnings("ignore")


class Space_SMOTE:
    def __init__(self, k=5, sampling_strategy=1, random_state=None,kmin=3,kmax=5):
        self.k = k
        self.kmin = int(kmin)
        self.kmax = int(kmax)
        self.sampling_strategy = sampling_strategy
        self.random_seed = random_state

    def fit_resample(self, x_train, y_train):
        np.random.seed(self.random_seed)
        maj_num = y_train.shape[0] - y_train.sum()
        generate_num = int(maj_num * self.sampling_strategy - y_train.sum())

        # normalize
        min_max_scaler = preprocessing.MinMaxScaler()
        min_max_scaler.fit(x_train)
        x_train_mm = min_max_scaler.transform(x_train)
        x_min_mm = x_train_mm[y_train == 1]

        # Generating middle samples
        nb_min = NearestNeighbors(n_neighbors=self.k + 1, algorithm='ball_tree').fit(x_min_mm)  
        dises_min, indexes_min = nb_min.kneighbors(x_min_mm)

        x_min = x_train[y_train == 1]
        gen_msg = np.zeros(shape=(1,4))
        x_sample = np.zeros(shape=(1,x_min.shape[1]))
        for k_dis_min, k_index_min in zip(dises_min, indexes_min):
            s1_x = x_min[k_index_min[0]]
            for i in range(1, len(k_index_min)):
                s2_x = x_min[k_index_min[i]]
                new_row = s1_x + 0.5 * (s2_x - s1_x)  # middle
                x_sample = np.vstack((x_sample,new_row))
                if k_index_min[0] < k_index_min[i]:
                    drop_rag = str(k_index_min[0]) + str(k_index_min[i])
                else:
                    drop_rag = str(k_index_min[i]) + str(k_index_min[0])
                gen_msg = np.vstack((gen_msg,[k_index_min[0],k_index_min[i],drop_rag,k_dis_min[i]]))

        gen_msg = np.delete(gen_msg, 0, axis=0)
        x_sample = np.delete(x_sample, 0, axis=0)
        # Get the index of the nearest neighbor samples
        sample_x_mm = min_max_scaler.transform(x_sample)
        nb_all = NearestNeighbors(n_neighbors=self.k, algorithm='ball_tree').fit(x_train_mm)  
        dises_sample, indexes_sample = nb_all.kneighbors(sample_x_mm)

        knn_mins = []
        for k_dis_sample, k_index_sample in zip(dises_sample, indexes_sample):
            weight = y_train[k_index_sample].sum()
            knn_mins.append(weight)
        gen_msg = np.column_stack((gen_msg,np.array(knn_mins)))

        # select connecting lines
        save_list,save_index = np.unique(gen_msg[:,2],return_index=True)
        gen_msg = gen_msg[save_index]
        gen_msg = gen_msg[gen_msg[:, 4].astype(float).astype(int) >= self.kmin]
        gen_msg = gen_msg[gen_msg[:, 4].astype(float).astype(int) <= self.kmax]

        # Generate new samples
        x_generate_sample = np.zeros(shape=(1,x_min.shape[1]))
        for gen_i in range(generate_num):
            if gen_msg.shape[0] == 0:
                break
            msg_t = gen_msg[np.random.choice(gen_msg.shape[0])]    
            x1 = x_min[msg_t[0].astype(int)]
            x2 = x_min[msg_t[1].astype(int)]
            x_new = x1 + np.random.uniform(0, 1) * (x2 - x1)
            x_generate_sample = np.vstack((x_generate_sample,x_new))
        x_generate_sample = np.delete(x_generate_sample, 0, axis=0)
        # concat
        y_generate_sample = np.concatenate((y_train, np.ones(x_generate_sample.shape[0])))
        x_generate_sample = np.concatenate((x_train,x_generate_sample),axis=0)

        return x_generate_sample, y_generate_sample

